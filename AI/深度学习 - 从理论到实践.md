
# 介绍


- 神经网络:  
	[机器学习-神经网络](机器学习.md#神经网络)  

深度学习(Deep Learning). 随着神经网络不断发展, 人们将其从机器学习中独立出来, 成为一种单独的算法分支--深度学习.  

随着数据量的增加, 人们能够构建规模更大的神经网络, 取得的效果也越好, 至此, 深度学习也就兴盛起来.  


## 机器学习基础


- 模型:  
	一个函数, 可以是任何函数 ,在深度学习中专指神经网络模型.  
	神经网络是一种更加复杂的, 理论上能拟合任何函数的模型.  
	通过训练(调整)模型, 能让其更加接近(拟合)样本的输入输出, 从而使输入得到期望的输出.  
	在训练前需要选择合适的模型, (随机)初始化系数.  


- 代价(损失)函数:  
	一种评估模型是否拟合数据的函数(), 通过模型与样本判断模型是否拟合样本数据.  
	更重要的是, 可以得到模型对其系数(参数)的导数, 以此可以使代价函数减小(梯度下降), 即更加拟合样本数据.  


## 符号说明

特征向量: n_x.  
样本矩阵(m个样本): X,  $n_x * m$ 或 $m * n_x$.  
样本标签: Y, 1 * m 的向量.  


**以逻辑回归为例**  

输出(预测值): $\hat{y} = P(y=1\mid x) = \sigma(w^T x + b)$  
σ: sigmoid函数, $\sigma(z) = \frac{1}{1+e^{-z}}$  
w, b: 神经网络中的参数, 这里将其从θ中分离成两个独立的参数, b 为偏置项(常数项).  

$u = w^T x$  
$v = u + b$  

损失函数(cost):  $\log 默认为 \ln$  
$$J(\omega , b) = - \frac{1}{m} \sum^m_{i=1} \left[ y^i \log \hat{y^i} + (1-y^i) \log(1-\hat{y^i}) \right]$$
$$\frac{dJ}{d\hat{y}} = - \frac{y}{\hat{y}} + \frac{1-y}{1-\hat{y}}$$ 
梯度下降:  
$w := w - \alpha \frac{dJ(w)}{dw}$

反向传播:  
$d_{var}$ : 损失函数 J 对中间变量的偏导.  

神经网络:  
L: 神经网络层数, 不包括输入层.  
$n^{[l]}$ : 第 $l$ 层神经网络.
$a^{[l]}$ : 第 $l$ 层的激活函数.  


## 向量化

在神经网络的计算中一律使用 向量/矩阵, 而不使用 for循环, 各计算库都对 矩阵计算 进行了优化, 可以更好地利用 CPU/GPU 的并行能力, 极大地提升计算速度.  


# 神经网络

$a^{[l]}_{i}$ : 第 l 层, 第 i 个节点.  
每个节点都会计算: $z = w^T x + b$ , $a = \sigma(z)$ 

对于每一层隐藏层来说:  
$Z = W^T X + B$ , $A = \sigma(Z)$  
> W: 模型参数, n \* n 矩阵;  
> X: 输入值, n \* m 矩阵;  
> B: 模型参数(偏置/常数项), 1 \* n 向量.  
> n: 等于上一层的 节点/输入 的数量.  


### 激活函数

激活函数要求为一个非线性函数, 用 g(z) 表示.  
sigmoid函数: $\sigma(z) = \frac{1}{1 + e^{-z}}$ $\sigma'(z) = a(1-a)$  
tanh函数: $tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$ $tanh'(z) = 1 - a^2$  
\[注]: a为激活函数的输出.  

tanh函数几乎在所有场合都比 sigmoid函数更优秀.  
sigmoid函数一般只作为二元分类输出层的激活函数.   

上面两个函数都有一个问题, 当 z 非常大/小 时, 其导数接近 0, 这会使梯度下降变得非常缓慢.  

线性修正单元:  $a = max(0, z)$  
$$
ReLU(z) = \left \{
\begin{align}
	0 \quad if  \quad z \lt 0 \\
	z \quad if  \quad z \geq 0 \\
\end{align}
\right.
$$
一般默认使用 ReLU.  

- 使用激活函数的必要.  
	当不使用或者其为线性时:
	$a_1 = w_1 x_1 + b_1$  
	$a_2 = w_2 a_1 + b_2 = w_2 w_1 x_1 + w_2 b_1 + b_2$   
	w_2 与 w_1 * w_2 并没有什么区别, 常数项也一样.  
	无论多少层隐藏层都和一层没有区别, 或者没有隐藏层.  


### 反向传播

通过正向传播可以计算损失(代价), 通过反向传播的链式求导法则可以计算神经网络中各参数的导数, 来实现梯度下降.  

- 正向传播:  
	$z = w^T x + b$  
	$a = g(z)$  
	$J(W, B) = \frac{1}{m} \sum^m_{i=1} l(\hat{y}, y)$  
	
- 反向传播:  
	J()为逻辑回归的代价函数.  
	$g(z) = sigmoid$  
	输出层: $dZ = \hat{Y} - Y$  
	隐藏层: $(dZ)^{n-1} = (W^n)^T (dZ)^{n} * g'(z)^{n-1}$  
	$dW = \frac{1}{m} dZ \ X^T$  
	$dB = \frac{1}{m} np.sum(dZ, axis = 1, keepdims=True)$  


### 随机初始化

偏置项 b 全部初始化为 0, 没有任何问题.  
但如果 w 全部为 0, 则节点会完全对称(X矩阵每一列都相同), 迭代时梯度下降也会完全对称($dW = \frac{1}{m} dZ \ X^T$).  
所以 W 会随机初始化为在 0 附近的值(0+-0.03). 接近 0 是因为这样经过激活函数后仍接近 0, 此时激活函数的梯度(导数)较大, 下降比较快.  


### 超参数

一般的参数指各层网络中的 W, b.  
其他的例如, 学习率α, 迭代次数, 隐藏层层数... 这些参数在一定程度上会影响最终的 W,b 的值, 称为**超参数**.  

超参数的值需要人为设定, 且难以一开始就知道其最优值, 需要不断测试并进行修改.  



# 训练

## 数据集

数据集会被分成 训练集, 交叉验证集, 测试集. 不同数据集应满足同一分布.  
训练集: 用来迭代参数.  
(交叉)验证集: 检测哪种算法更有效.  
测试集: 测试模型的效果.  

在机器学习的时代, 其分割比例一般为 7:3:0, 6:2:2.  
在大数据时代, 数据量变得非常庞大(百万), 可以将数据更多地分配在训练集上, 其比例可能是 98:1:1 或是 99.5 : 0.25 : 0.25.  


## 偏差与方差

[机器学习-模型诊断](机器学习.md#模型诊断)

- 欠拟合:  
	对训练集和测试集的数据预测准确率都不高, 即高偏差.  

- 过拟合:  
	对训练集的数据拟合非常好, 准确率非常高, 但对测试集数据的准确率非常低, 即高方差.  

高偏差与高方差是可能同时出现的, 既欠拟合又过拟合.  
高偏差与高方差是个相对的概念, 并没有绝对的分界线区分是否为高偏差或是否为高方差.  
![高偏差高方差](https://pic.imgdb.cn/item/64c1fc7e1ddac507ccab78d2.jpg)

### 正则化

正则化是解决过拟合问题的主要方法.  

$$J(w,b) = \frac{1}{m} \sum^m_{i=1} l(\hat{y},y) + \frac{\lambda}{2m} \| w \|^2$$
代价函数后加上的 $\frac{\lambda}{2m} \|w\|^2$ 为**正则项**(l_2范数).  
$\|w\|^2 = w^T w$  

加上后, 会让参数尽量小, 且比较接近, 这样函数会更加平滑. 但λ的值过大会让模型欠拟合.  

- dropout正则:  
	dropout正则每次训练会随机使神经网络中的节点失效, 仅使用剩下的节点进行计算和梯度下降.  
	
	`d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep-prob`  
	> a3: 第3层的激活值.  
	> keep-prob: 保留概率, (0, 1).  
	> d3: bool索引, 进行逻辑判断后对应的节点列表.  

	`a3 = np.multiply(a3, d3)`  
	> a3 与 d3 相乘, 可以去除判断为 false 的节点, 使其为 0.  

	`a3 /= keep-prob`  
	> 保证 a3 的期望值不变.  

	过拟合是样本数少或特征数多造成的. 此方法也是在减小神经网络的复杂程度, 会将权重分散, 使模型更好地拟合样本数据.  	


## 归一化处理

计算数据均值: $\mu = \sum^m_{i=1} x^i$.  
数据都用均值表示: $x^i -= \mu$.  
归一化: $\sigma^2 = \frac{1}{m} \sum^m_{i=1} (x^i)^2$  $x^i /= \sigma^2$

这样就可以控制数据的均值和方差, 比较规则的数据能使代价函数更快收敛.  


## 梯度

### 梯度消失与梯度爆炸

在反向传播过程中:  
$(dZ)^{n-1} = (W^n)^T (dZ)^{n} * g'(z)^{n-1}$  

当神经网络层数较多时,  
g'(z) < 1, 其导数值会逐渐减小.  
g'(z) > 1, 其导数值会逐渐增大.  

$z = \sum^m_{i=1} x^i w^i$  
w 初始化应在一个合理的区间.  
`w = np.random.rand(shap) * np.sqrt(1/n)`  
如果激活函数为 ReUL, 换成 2/n 会有更好的效果. n 为上一层神经元数量.  
w 会与特征向量处于相似的分布中.  


### 梯度检测

对于神经网络中的每个参数进行梯度检测

导数计算公式:  
$$f'(x) = \frac{f(x+\epsilon) - f(x - \epsilon)}{2\epsilon}$$

梯度计算:
$$
d\Theta^{[i]}_{approx} = \frac{J(\theta_{i} + \epsilon) - J(\theta_{i} - \epsilon)}{2\epsilon}
$$
梯度检测:  
$$
check = \frac{\| d\Theta_{approx} - d\theta \|}{\| d\Theta_{approx} \| + \| d\theta \|}
$$
> 其值应小于 10^(-3), 一般在 10^(-7).  
> dθ为反向传播过程中计算出的梯度值.  

一般在训练过程中不会进行梯度检测, 其计算非常慢, 只在调试的时候用于检测.  
dropout正则 与 梯度检测不兼容.  


## 超参数的调节

- 目前的超参数:  
	- 学习率: α.  
	- 动量: β, β_1, β_2, ε.  
	- 隐藏层层数: layers.  
	- 隐藏层单元数: hidden units.  
	- 学习率衰减: learning rate decay.  
	- 数据组大小: mini-batch size.  

- 最重要的为 α.  
- 其次为 β, 隐藏层单元数, mini-batch大小.  
- 然后是 隐藏层数, 学习衰减率.  
- 最后 动量其他部分一般固定为 0.9, 0.999, 10^-8.  


- 调整过程:  
	- 在一定范围内随机取值.  
	- 确定效果比较好的各参数范围.  
	- 缩小取值范围.  
	- 继续随机取值.  
> 有时不希望随机的概率为均匀分布(参数对结果的影响非线性), 可以对随机数再用对数或指数, 即对随机值进行各种后期处理.  


- 可以根据不同的资源采用不同的调节方案:  
	- 当计算机无法承担多个模型的训练时:  
		可以边训练边适当调节参数.  
	- 当计算机资源充足时:  
		可以同时训练多个不同的模型, 来对比其效果.  




# 优化

## mini-batch

在向量化计算过程中, 样本数据为 n x m 的矩阵.  
当 m 过大时(百万), 计算速度仍然很慢, 负担较大.  

此时, 可以将训练数据分成小块, 每个batch有合适的训练数据量.  
mini-batch_size 的选择, 其应在 1 至 m 之间. 越大迭代越缓慢, 越小下降方向越不稳定.  

![迭代对比](https://pic.imgdb.cn/item/64c865721ddac507cc20f930.png)


- 学习率衰减
	因为其梯度下降方向不一定是最低点, 其最后可能会在最低点附近不断波动, 难以收敛.  
	可以通过减小学习率来使其更容易收敛, 即学习率衰减.  
	α = α_0 / (1 + decay-rate * epoch-num)  
	> α_0 : 初始学习率.  
	> decay-rate : 衰减率.  
	> epoch-num : 迭代数.  
	
	也有一些其他的衰减公式...  


## 指数加权平均*

以指数式递减加权的移动平均 来计算一组数据的平均值.  
逐个计算前n个数据的带权平均值, 越靠后的数据加权越重, 靠前数据的权重指数递减.  

$v_{i} = \beta \ v_{i-1} + (1-\beta)x_{i}$  
> v : 平均值  
> x : 数据  
> β: 参数, 取 0.9  

其可视为计入最近 $\frac{1}{1-\beta}$ 个数据的值, 其权重约为 1/e.  

![指数加权移动平均](https://pic.imgdb.cn/item/64c865791ddac507cc2105fd.png)


β值影响的是"过去"与"现在"的权重. 其增大时, 过去的权重增大, 变化会"延迟"; 减小时, 现在的权重增大, 变化更加敏感.  
![更改β](https://pic.imgdb.cn/item/64c865801ddac507cc2110ac.png)


- 偏差修正:  
	当 $v_0$ 初始化为 0 时, 由于其之前的数据被视为0, 所以靠前的计算值会非常低, 而不是像上图一样接近数据的均值. 所以一般需要有偏差修正.  
	$v_i = v_{i}/(1 - \beta^i)$, β^i 随 i 增加而逐渐接近 0.  


## 梯度下降中的摆动


由于特征向量各维度的初始值与梯度不同, 而它拥有相同的学习率. 容易使得一边学习快, 在最小值附近摆动; 另一边学习慢.  

![摆动梯度下降](https://pic.imgdb.cn/item/64c8a48d1ddac507cca17efe.png)

减小摆动的幅度可以让其往更接近最小值的方向前进, 使损失函数更快收敛.  

- 动量梯度下降法

	计算出 dw, db 后:  
	V_dw = β V_dw + (1-β)dw  
	V_db = β V_db + (1-β)db 
	> β: 动量(momentum).  
	> (1-β) 有时会被删去, 仅影响最佳的 α 值  
	
	w -= αV_dw  
	b -= αV_db  
	如果梯度在正负值摇摆, 其叠加值(V)会趋近 0, 如果为单一正负, 其获得加速.  


- RMSprop  

	S_dw = β S_dw + (1-β)(dw)^2  
	S_db = β S_db + (1-β)(db)^2  
	$W = W - α \ dw/\sqrt{S_{dw}}$  
	$b = b - α \ db/\sqrt{S_{db}}$  


- Adam优化算法

	Adam算法结合了**动量梯度下降**和**RMSprop**.  

	步骤:  
	初始化 V_dw = 0, S_dw = 0, V_db = 0, S_db = 0.  
	计算出 dw, db.    
	$V_{dw} = \beta_{1} V_{dw} + (1-\beta_{1}) dw$  
	$V_{db} = \beta_{1} V_{db} + (1-\beta_{1}) db$  
	$S_{dw} = \beta_{2}S_{dw} + (1-\beta_{2})(dw)^2$  
	$S_{db} = \beta_{2} S_{db} + (1-\beta_{2})(db)^2$  	

	$V_{dw} = V_{dw}/(1-(\beta_{1})^t)$, $V_{db} = V_{db}/(1-(\beta_{1})^t)$.  
	$S_{dw} = S_{dw}/(1-(\beta_{2})^t)$, $S_{db} = S_{db}/(1-(\beta_{2})^t)$.  

	$w = w - \alpha V_{dw} / \sqrt{ S_{dw} + \epsilon }$, $b = b - \alpha V_{db} / \sqrt{ S_{db} + \epsilon }$.  
	加上 $\epsilon$ 是为了避免分母为 0, 其值一般非常小.  

	各超参数值的选择(推荐值):  
	α: 需要不断调整.  
	$\beta_1$ : 0.9  
	$\beta_2$ : 0.999  
	$\epsilon$ : 10^(-8), 影响不大.  


## 局部最优问题

在说到局部最优问题时, 一般想的可能是这样的:  
![局部最优](https://pic.imgdb.cn/item/64cb65f71ddac507ccb71ade.png)
但在神经网络中, 零梯度点往往是鞍点.  
在几千上万维度的空间中, 一个点所有维度的梯度都为零的概率非常小. 所以更可能碰到鞍点而不是局部最优.  
![鞍点](https://pic.imgdb.cn/item/64cb681d1ddac507ccbc5e5e.png)

在梯度下降过程中可能会遇到"平稳段", 此时梯度趋近零, 学习速度非常慢, 用Adam算法也许会有改善(可以加速).  




## batch 归一化

如果对输入参数进行归一化处理, 可以使梯度下降进行得更顺利. 但对于多层的神经网络, 只有第一层的输入是归一化的.  
那是否可以对每一层的输入都进行归一化呢?  


- 对于每层隐藏层:  
	计算出所有z值(激活函数之前的值), $z^1, \dots, z^m$.  
	计算均值: $\mu = \frac{1}{m} \sum_{i} z^i$  
	计算方差: $\sigma^2 = \frac{1}{m} \sum_{i} (z^i - \mu)^2$  
	标准化正态分布: $Z^i_{norm} = \frac{z^i \mu}{\sqrt{ \sigma^2 + \epsilon }}$  
	其他正态分布: $\tilde{Z}^i = \gamma Z^i_{norm} + \beta$, β为均值, γ为方差.  
	因为一些激活函数(如 sigmoid), 其 0 附近为线性部分, 所以需要改变输入的分布.  

	现在, 可以用 $\tilde{Z}^i$ 代替 $Z^i$,  


- 在使用batch归一化后:  
$$X \stackrel{w, b}{\to} Z \stackrel{\beta,\gamma}{\to} \tilde{Z} \to g(\tilde{Z}) = a$$
> $\beta, \gamma$ : 和其他参数一样可以根据梯度进行下降学习.  
> 由于进行了归一化, 常数项参数 b 对于输出没有作用, 可以设为0, 或直接去掉.  


- 作用:  
	- 如果训练集与测试集的分布不一致, 往往需要重新训练整个神经网络. 因为每一层的输入输出相互关联. batch归一化后, 输入(输出)的分布前后保持一致, 可以更快地进行学习.  


- 在 mini-bitch 中的应用:  
	由于每个 mini-bitch 的均值/方差不尽相同, 与整体的均值/方差不一致, 在处理时会用指数加权平均来代表整体的均值/方差.  


# Softmax回归

属于逻辑回归的多元分类.  

如果需要分n类, 输出应为n维向量, 表示分成各类的概率.  
如分成四类(A类, B类, C类, 其他/Other), $\hat{h} = [P(A), P(B), P(C), P(O)]$  

Softmax激活函数:  
在输出层时, 计算:  
$t = e^z$  
$a = \frac{t}{\sum^n_{i=0} t_{i}}$  
> z, t, a 应为 n 维向量.  

也就是从数值转化为百分比, 但不是线性的, 可以处理负数部分.  

一般种类数量会用 C 表示.  

- 训练:
	- 损失函数: $l(\hat{y}, y) = - \sum_{j=0}^C y_{j} \log(\hat{y}_{j})$  


# 策略

对于模型的效果, 当其表现不同时, 需要采取不同的策略来进行调整.  


## 准确率与召回率


$准确率(P) = \frac{预测为真 \& 实际为真}{预测为真}$  

$召回率(R) = \frac{预测为真 \& 实际为真}{实际为真}$  

[不对称性分类的误差评估](机器学习.md#不对称性分类的误差评估)  

F1 分数:  
	F1 分数结合了 查准率(P)与 查全率(R), 作为评判标准.  
	调和平均数: $F1 = 2/ (\frac{1}{R}+\frac{1}{P})$  


如果有多个指标, 而不同模型对不同指标有高有低, 很难从多个指标中筛选最好的模型, 最好使用单一的实数(结合多个指标)来作为一个评判标准.  


## 标注错误

深度学习算法对随机错误很健壮, 但对系统性误差不健壮.  
即小部分的随机标注错误不影响模型的训练.  

系统性的错误可以在错误分析中, 显示其标签, 查看因标签错误的占比, 占比较大时就有必要去修正.  



## 迁移学习

如果已经训练好了一个猫类图片识别模型, 也可以更改输出层, 然后直接训练成其他图片识别分类模型. 因为在先前的训练中, 模型可能已经学会了一些图片识别的基本特征, 这样可以加速其他模型的训练.  
尤其是大模型迁移至小模型时, 已经积累的训练量可能非常有用.  


## 多任务学习

如果需要在一张图片中识别多个目标, 那么其输出为一个向量, 表示是否存在指定的目标.  
虽然可以训练多个模型来分别判断是否存在这些目标, 但其任务十分相似, 可以由一个稍大些的模型一起承担.  

其与多分类模型有些区别, 多分类会在目标中选择一个, 但多任务每个都是单独判断的.  



## 端到端的深度学习

即输入端到输出端.  

如果有一个语音识别任务, 可以先将音频拆分为音节, 然后再转换为文本. 但在训练数据足够和网络够大的情况下, 直接输入音频, 输出文本的模型效果要更好.  

在另一些情况下, 如人脸识别, 更推荐拆分任务: 先定位人脸位置, 并进行合适的缩放, 再进行识别.  

端到端的学习对数据量有非常大要求, 当确信人为地设计流程是有必要且有效的时候, 也不必用端到端的学习方法.  


# 计算机视觉

## 卷积

卷积常用来作简单的图像处理, 如垂直边缘检测, 其为一个 3 x 3 矩阵. 也被称为过滤器, 卷积核.  
图像为三维矩阵, 灰度图像为二维.  

- 卷积运算:  
	将卷积核覆盖于图像上, 作乘算, 得到一个数值, 再不断移动进行乘算, 即可得到一个比原图像小一圈的矩阵.  

![卷积运算](https://pic.imgdb.cn/item/64e82e7c661c6c8e54e5fb6a.gif)  


- 垂直边缘检测:  
	3 种卷积核:  

| 1   | 0   | -1  |     | 1   | 0   | -1  |     | 3   | 0   | -3  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1   | 0   | -1  |     | 2   | 0   | -2  |     | 10  | 0   | -10 |
| 1   | 0   | -1  |     | 1   | 0   | -1  |     | 3   | 0   | -3  | 

> 如果两边颜色相近, 计算结果会趋近 0, 呈深色.  
> 如果两边颜色不同(垂直边缘), 计算结果较大(取绝对值), 呈白色.  
> 通过调整数值也可以得到不同角度的边缘检测, 或是其他过滤器.  

- padding:  
	使用过滤器之后, 图像会缩小.  
	原图像大小: n x n, 过滤器大小: f x f.  
	计算的图像大小: (n - f + 1) x (n - f + 1).  

	对于角落, 边缘的像素的使用次数会比中间的像素更少.  

	为了解决这些问题, 可以进行 padding(扩充).  
	在图像外围填充值为 0 的像素点(p层).  
	扩充后图像边长为: n + 2p.  
	如果想过滤后大小与原来一致, p = (f - 1)/2.  

- 卷积步长:  
	指卷积核在图像上移动的步长, 上图演示的步长即为 1.  
	当步长为 s 时, 输出的图像边长为: (n + 2p - f)/s + 1.  
	如果不是整数, 则向下取整.  

- 三维卷积:  
	图像的第三维为颜色通道(channel), 卷积核的第三维长度(深度)需要与其一致.  
	卷积核的移动与二维时一致, 得到的结果为二维矩阵. 
	过滤器可以有多个, 多个过滤器得到的结果可以叠加在一起, 计算结果的第三维程度等于过滤器个数.  


## 单层卷积网络

三维图像数据通过不同卷积核得到多个二维矩阵.  
矩阵加常数后的结果再通过激活函数即为卷积层输出.  

在非卷积网络中:  
$z = wa + b$  
$a = g(z)$  

在卷积层中:  
卷积核就相当于参数w.  

- 符号:  
	f: 过滤器大小(边长).  
	p: 图片扩充层数.  
	s: 步长.  
	n_H, n_W, n_C: 高, 宽, 通道数.  
	输出的通道数等于过滤器的个数.  
	卷积层的过滤器通道数等于输入的通道数.  


单层的卷积层以此不断叠加形成卷积网络.  
最后的输出放入Softmax回归函数中.  

虽然仅用卷积层也可能构建出很好的神经网络, 但一般依然会增加 **池化层(Pooling/Pool)**, **全连接层(Fully connected/FC)**.  


## 池化层

池化层用来减小模型大小, 提高计算速度, 提高特征提取的健壮性.  
相邻像素为一块, 成为一个整体, 像素值选取最大值.  
简单来说, 即将 "高清图片" 压缩为 "像素图片".  

其与卷积一样可以选取合并(过滤器)的边长, 步长. 但其"计算"方式不同.  
输入输出的通道数量保持一致.  

- 输出像素值:  
	其值也可以选取中位数, 最小值, 平均值, 但相邻像素一般差距不大, 选最大值即可.  

- 过滤器大小与步长:  
	一般: f = 2, s = 2.  

一般会在一个卷积层后连接一个池化层, 两个加起来算作一整层.  


## 全连接层

在卷积层和池化层之后, 将结果化为一维向量, 接入的普通隐藏层即全连接层. 也会有多层. 最后再连接Softmax.  

网络中的大部分参数都会集中在全连接层中.  



# 视觉神经网络模型

## 经典网络结构

### LeNet-5

LeNet-5 是针对灰度图像训练的(手写体字符识别).  

结构:  
输入(32x32x1) -> 卷积层(f=5,s=1,n=6) -> (28x28x6) -> 池化层(14x14x6) -> 卷积层(f=5,s=1,n=16) -> (10x10x16) -> 池化层(5x5x16) -> 全连接层(120) -> 全连接层(84) -> 输出  

随着卷积与池化, 图片大小不断减小, 通道数量不断增加.  
在当时的计算机性能下, 每个过滤器对应其输入的不同通道, 现在一般不这样用.   


### AlexNet

输入:  
227x227x3

C1:  
f = 11, s = 4, n = 96.  
-> 55x55x96

MaxPool:  
f = 3, s = 2.  
-> 27x27x96

C2:  
f = 5, p = 2, s = 1, n = 256.  
-> 27x27x256

MaxPool:  
f = 3, s = 2.  
-> 13x13x256

卷积:  
... -> 13x13x384 -> 13x13x384 -> 13x13x256

MaxPool:  
f = 3, s = 2.  
-> 6x6x256

全连接:  
9216 (fc)-> 4096 (fc)-> 4096 -> SoftMax(1000)  


### VGG-16

输入:  
224x224x3

Conv:  
f = 3, s = 1, p = 1.  

Pool:  
f = 2, s = 2.  

224x224x3 (Covn)-> 224x224x64 (Pool)-> 112x112x64 (Covn)-> 112x112x128 (Pool)-> 56x56x128 (Covn)-> 56x56x256 (Pool)-> 28x28x256 (Covn)-> 28x28x512 (Pool)-> 14x14x512 (Covn)-> 14x14x512 (Pool)->  7x7x512 (FC)-> 4096 (FC)-> 4096 



## 残差网络


当神经网络的层数增多时, 容易引起梯度消失/爆炸的问题.  
也容易出现退化的问题, 随着层数的增加, 训练集的准确率却下降了.  
原因可能是随着深度的增加, 训练难度也增加, 导致训练效果不佳.  

![][D:\word文档\MarkDown文档\image\机器学习\网络退化.png] 

### 残差块:  

Residual block.  

在一般的前向传播过程中:  
$z = wa + b$  
$a = g(z)$  
这称为"主路径".  

捷径(远跳连接):  
前面的激活值会参与后面激活值的计算.  
$a^{l+2} = g(z^{l+2} + a^{l})$  

一个残差网络由许多残差块构成.  
![][D:\word文档\MarkDown文档\image\机器学习\残差网络.png]

### 残差块的效果

如果说深度的增加会带来负面效果, 那么至少要使深层网络的效果不输给浅层网络.  

在 $a^{l+2} = g(z^{l+2} + a^{l})$ 中, 如果 z = 0, 激活函数为ReLu, 则可以认为 $a^{l+2} = a^{l}$.  
因为学习恒等函数非常简单, 这样深度的增加就不会带来负面影响, 而且如果它能学到有用的特征, 那就能带来正向提升.  

残差网络图片识别模型:  
![](D:\word文档\MarkDown文档\image\机器学习\残差网络图片识别.png)







----  
























# 深度学习框架

深度学习的框架每天都在进步, 框架的推荐需要实时从网络上浏览, 先介绍选择框架的标准.  

- 便于编程.  
- 运算速度.  
- 真正开放(开源+良好的管理).  


框架:  
- TensorFlow:  
	由谷歌维护, 目前主流的深度学习框架, 入门难度较大.  

- Keras:  
	对TensorFlow的高级集成API, 对小白友好易入门的框架.  

- Caffe:  
	...

- PyTorch:  
	Facebook团队分布的框架(2017), 近年来的关注度不断上升.  


# Pytorch


## 张量

在pytorch中, 使用张量表示 n维数组(矩阵), 一般都使用张量作为数据容器.  
秩, 轴, 形状是张量最重要的属性.  
class: torch.Tensor


### 张量的属性

- 秩:  
	代表张量的维度数.  
	或者说是矩阵的阶数.  

- 轴:  
	张量有多少个维度, 其就有多少个轴.  
	每个轴的长度可以不同.  

- 形状:  
	各个轴的长度组合即可描述张量的形状.  

- 其他属性:  
	- dtype(数据类型):  
		张量中的数据的类型, 每种都分一个CPU版, GPU版(cuda).  
	- device(驱动):  
		分为CPU和GPU. 张量之间的操作必须位于同一设备上.  
	- laylout(布局):  
		默认为 strided, 无需改变.  


### 张量的创建

可以从已有数据构建张量.  
```python
data = np.array([1,2,3])

# 构造函数
torch.Tensor(data)

# 工厂函数
# 深拷贝(Copy Data)
torch.tensor(data) # ☆
# 浅拷贝(Share Data)
torch.as_tensor(data) # ☆
# 浅拷贝(Share Data), 只接受numpy数组, 所以as_tensor更为常用.  
torch.from_numpy(data)
```
> 工厂函数会做数据类型推断来指定 dtype, 构造函数默认为 float32.  
> 工厂函数一般有过多的参数选择, 现在普遍选择使用工厂函数. tensor 和 as_tensor.    


其它方式.  
```python
# 创建 nxn 的二维张量, 主对角线为 1, 其余为 0.  
torch.eye(n)

# 创建 mxn 的二维张量, 全为 0.
torch.zeros(m, n)

# 全为 1.
torch.ones(m, n)

# 随机数
torch.rand(m, n)
```


### 张量常用操作


- 重塑  
	`tensor.reshape(x,y,z...)`  
> 参数为重塑后的形状, 需要确保数据能够完全填充, 值为 -1 时可代表任意长度.  
> 可以增加维度, 或减少维度.  

- squeeze  
	`tensor.squeeze()`  
	`tensor.unsqueeze()`  
> 移除所有长度为 1 的轴, 或增加长度为 1 的维度.  

- flatten()  
	`t.reshape(1, -1)`  
	`t.squeeze()`  
> 其为特殊的重塑操作, 将高维的数据压缩至一维.  
> 从卷积层到全连接层时, 通常需要此操作.  
> reshape(-1) 也可以得到同样的结果.  


- 运算  
	add(+), sub(-), mul(\*), div(/)  
> 张量之间可以进行运算, 其形状必须相同.  
> 其为同位置元素间的运算.  
> 广播机制同样适用.  

- 广播机制  
	低维度的张量自动向高维度增加长度为 1 的维度, 直到维度相同.  
	当所有除长度为 1 的维度之外的其他维度长度都相同, 则可以进行"复制", 使两个张量的形状相同.  

- 其他运算(返回的都是tensor对象)  
	- sum(dim): 求和.  
		dim: 轴. 为 0, 竖直求和; 为 1, 水平求和. 无, 全部求和.  
	- prod, mean, std.  
	- argmax(): 返回最大值的(flatten后的)下标.  



## 数据集


### MNIST数据集

这是一个著名的手写数字数据集(0-9).  

其共有 7万 张图片(28x28x1).  
6万 为训练集.  
1万 为测试集.  

- Fashion-MNIST:  
	一个有关时尚的数据集, 数据来自 Zalando(总部位于德国的跨国时尚贸易公司).  
	其也有十个分类: T恤, 裤子, 套衫, 裙子, 大衣, 凉鞋, 衬衫, 运动鞋, 包, 裸靴.  

	对学术界来说分类数字似乎已经有点无聊的, 所以收集的与其集合非常相似的这个时尚数据集.  


### torchvision

torchvision 为 pytorch 中一个用于视觉的独立的包, 会随pytorch一起下载.  

pytorch 为数据处理提供了两个类: DataSet, DataLoader.  

- DataSet:  
	表示数据集的抽象类.  
```python
# 抽象数据集的具体实现样例(金融时间序列)
class OHLC(DataSet):
	def __init__(self, csv_file):
		self.data = pd.read_csv(csv_file)

	def __getitem__(self, index):
		# 得到数据帧中指定索引位置的行
		r = self.data.iloc[index]
		# 得到其标签
		label = torch.tensor(r.is_up_day, dtype=torch.long)
		# 得到其数据(normalize, 归一化处理)
		sample = self.normalize(torch.tensor([r.open, r.high, r.low, r.close]))
		return sample, label

	def __len__(self):
		return len(self.data)
```

- 获取数据集:  
```python
train_set = torchvison.datasets.FashionMNIST(
	root='./data/FashionMNIST',      # 下载训练集的储存位置
	train=True,                      # 训练数据或是测试数据
	download=True,                   # root参数指定的位置没有数据时会从网络上下载
	transform=transforms.Compose([   # 内置的转换器, 将图片转换为张量
		transforms.ToTensor()
	])
)
```

- DataLoader:  
	封装数据集并提供对底层数据的访问.  
	能够实现对数据的各种处理, 包括分组(batch).  

- 加载数据集:  
`train_loader = torch.utils.data.DataLoader(train_set, batch_size)`  
> train_set: 数据集.  
> batch_size: 分组大小, 默认为 1.  

- 访问单个样本:  
```python
sample = next(iter(tran_set))
	# iter() 为可迭代对象创建一个迭代器
	# next() 使迭代器前进并返回元素

len(sample)
type(sample)

# sample 包含两个元素(图片/数据(tensor), 标签(int))

image, label = sample
	# 其等效于两行代码
	# image = sample[0]
	# label = sample[1]

image.shape    # torch.Size([1, 28, 28])

plt.imshow(image.squeeze(), cmap='gray')  # 用 灰色 表示 灰度
print('label:', label)
```
> 如果iter中传入的为 train_loader, sample的两个元素都会变成列表.  

- 多个样本展示:  
```python
# (网格)将多幅图像组成一幅, 指定一行10幅
grid = torchvision.utils.make_grid(images, nrow=10)
# 创建画布并展示
plt.figure(figsize=(15,15))
plt.imshow(np.transpose(grid, (1, 2, 0)))
print('labels', label)
```


## 模型

### 模型类的定义方式

torch.nn: pytorch的神经网络库.  
其中的类: Module, 是所有神经网络的父类.  

自定义的模型需要继承 Module 类, 将网络的层定义为类属性, 并实现向前传播方法.  

```python
import torch.nn as nn

class Network(nn.Module):
	def __init__(self):
		# 用Model初始化自定义模型.
		super(Network, self).__init__()
		# 创建隐藏层对象
		# 卷积层
		self.conv = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5)
		# 池化层
		self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)
		# 全连接层(full connected)/线性层(linear)/密集层(dense)
		self.fc = nn.Linear(in_features = 6*12*12, out_features = 10)

	def forward(self, t):
		# 经过卷积层和激活函数(ReLu)
		t = torch.relu(self.conv(t))
		# 池化
		t = self.pool(t)
		# 压缩成 n(batch_size)行 6*12*12列
		t = t.reshape(-1, 6*12*12)
		# 全连接
		t = self.fc(t)
		return t
```
> 隐藏层的个数及其种类都可以通过类属性定义.  

### 三种网络层

- 卷积层(convert):  
	Conv2d : 二维卷积层类.  
	- in_channels : 输入层数(通道数).  
	- out_channels : 输出层数(通道数).  
	- kernel_size : 卷积核大小.  
	
	第一个卷积层的输入层数(通道数)为数据集图片的通道数.  
	之后每层的输入层数为前一层的输出层数.  

- 池化层(pool):  
	pass

- 全连接层(fc):  
	Linear : 线性层类.  
	- in_features : 输入特征数.  
	- out_features : 输出特征数.  
	
	全连接层第一层的输入特征数为前一层(卷积层/池化层)的像素数量(特征数).  
	其后的输入数为前一层的输出数.  
	最后一层的输出应为分类的数量.  

网络层都实现了__call__方法, 在调用其实例时会进行对应运算, 如: $Y = AX + B$.  
示例:  
```python
# 输入值
in_features = torch.tensor([1,2,3,4], dtype=torch.float32)
# 权重矩阵
weight_martix = torch.tensor([
	[1,2,3,4],
	[2,3,4,5],
	[3,4,5,6]
], dtype=torch.float32)
# 创建一个线性层, 无偏置项
fc = nn.Linear(4, 3, bias=False)
# 将线性层的初始权重改为上方自定义的权重
fc.weight = nn.Parameter(weight_martix)
# 运算
output = fc(in_features)
output
```  


- 参数:  
	模型名.层名.weight, 通过访问模型实例的神经层对象的权重对象(Parameter)可以查看所有的权重数值.  
	network.parameters(), 内置方法, 可以得到权重(weight)和偏差(bias)组成的迭代对象.  
	- 卷积层参数量: out * in * size * size.  
	- 全连接层参数量: out * in.  


### 向前传播


通过在初始化方法中定义各网络层.  
在向前传播方法中使用已定义的网络层实现向前传播.  

```python
def forward(self, x):
	# 卷积层第一层, 激活函数, 池化
	x = self.pool(torch.relu(self.conv1(x)))
	# 卷积层第二层 ...
	# ...
	# 全连接层之前将数据压成(batch_size行n列)
	x = x.reshape(-1, n)
	# 全连接层第一层
	x = torch.relu(self.fc1(x))
	# ...
	# 最后输出层(全连接层)
	x = self.fc(x)
	# x = torch.softmax(x, dim=1)

	return x
```


## 训练过程


CNN的输入通常为图片, 其数据转为张量后的形状可以表示为:  
shape = \[B ,C, H, W]  
> B: 样本数量(batch), 通常输入为一组数据, 而非单个.  
> C: 通道数量, 1: 灰度, 3: RGB, 4: $RGB\alpha$.  
> H: 图片高度.  
> W: 图片宽度.  


得到 train_loader 后, 就可以用数据进行向前传播得到预测值(内部会调用向前传播方法).  
`pred = network(input)`  
> 预测值为 batch_size * 10 的张量, 代表为各分类的概率(经过Softmax后).  


可以设置 batch_size 来实现批量数据的训练:  
`data_loader = torch.utils.data.DataLoader(train_set, batch_size = 10)`  


- 训练过程:  
	训练分为多个周期(epoch), 每个周期都将用所有的训练集进行训练.  
	1. 向前传播:  
		`preds = network(images)`  
		`preds.argmax(dim=1)  # 取得每个输入的最大预测值下标`  
		
	2. 损失计算与反向传播:  
		交叉熵损失类: `loss = nn.CrossEntropyLoss()(output, label)`  
		反向传播: `loss.backward()`  
		之后会自动计算梯度, 查看: `print(network.conv1.weight.grad)`  

	3. 优化(梯度下降):  
		优化器: `optimizer = optim.Adam(network.parameters(), lr=0.01)`  
		> Adam 或是 SGD.  
		> 需要传入神经网络的参数.  
		> lr : 学习率, 默认 0.001  
		
		优化: `optimizer.step()`, 会更新权重(参数).  

	4. 最后只需要扩展至整个训练集并循环上述过程:  
		注意: <span style="color:orange">pytorch 会累加梯度值, 反向传播前应清除梯度: `optimizer.zero_grad()`</span>  

```python
# 加载数据, 损失函数, 优化器
train_loader = torch.utils.data.DataLoader(train_set, batch_size = 100)
optimizer = optim.Adam(network.parameters(), lr=0.01)
criterion = nn.CrossEntropyLoss()

# 训练次数
num_epochs = 5

print("开始训练...")

for epoch in range(num_epochs):
    # 记录总损失值
    total_loss = 0
    
    for batch in train_loader:
        # 一组样本
        images, labels = batch
		
        # 预测值与损失
        pres = network(images)
        loss = criterion(pres, labels)
		
        # 优化迭代
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
		
        total_loss += loss.item()
	
    print("周期:", epoch, "总损失值:", total_loss)

print("训练完成")
```


## 结果的整理与训练优化


### 混乱矩阵


对于模型预测的结果, 可以制作一个混乱矩阵来观察模型的预测情况.  
x轴为预测分类, y轴为真实类别.  
如此, 在对角线的数字代表预测正确的数量, 其他为各种错误的预测.  

1. 获取预测值
```python
def get_all_preds(model, loader):
	# 获取模型对数据集的全部预测值
	all_preds = torch.tensor([])
	for batch in loader:
		images, labels = batch
		
		preds = model(images)
		all_preds = torch.cat(
			(all_preds, preds),
			dim = 0
		)
	return all_preds
```

因为在收集预测值时不需要进行训练, 可以关闭梯度跟踪来提高运行效率.  
虽然梯度的计算是在运行反向传播时进行的, 但在前向传播时会缓存为反向传播计算准备的运算结果.  

```python
# 1. with...
with torch.no_grad():
	prediction_loader = torch.utils.data.DataLoader(tran_set, batch_size = 1000)
	train_preds = get_all_preds(network, prediction_loader)

# 2. 对函数添加装饰器
@torch.no_grad()
def ...
```

2. 预测值与目标值的集合  

由于模型的预测是对每个分类的可能性概率, 所以需要取最大的哪个.  
```python
# 压缩数据维度, 得到 样本量 X 2 的"混乱集合".
stacked = torch.stack(
	(
		train_set.targets,        # 目标值(样本标签值)
		tran_preds.argmax(dim=1)  # 最大预测值对应的分类
	),
	dim = 1
)
```

3. 制作混乱矩阵

```python
# 初始化
cmt = torch.zeros(10, 10, dtype=torch.int32) # 分类数量为 10

# 统计
for p in stacked:
	tl, pl = p.tolist()
	cmt[tl, pl] = cmt[tl, pl] + 1
```

统计过程有个库可以更快捷地实现:  
```python
# 绘制
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
# 这个库需要自己实现, 代码在下文
from resource.plotcm import plot_confusion_matrix

# 统计数据, cm与cmt一致
cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))

names = ('...','..')  # 存放各分类的名字, 作为表格的X/Y轴标签.  
plt.figure(figsize=(10, 10))
plot_confusion_matrix(cm, names)
```

```python
def plot_confusion_matrix(cm, classes)
	# 似乎找不到了...
	pass
```


### 拼接与叠加


拼接: 在现有的轴上连接一系列张量.  
叠加: 在新的轴上叠加张量.  

```python
import torcht1 = torch.tensor([1,1,1])
t1.unsqueeze(dim=0)
# tensor([[1, 1, 1]]) 1 x 3
t1.unsqueeze(dim=1)
# tensor([[1],[1],[1]]) 3 x 1
```

在 pytorch 中使用 cat 与 stack 进行 拼接 与 叠加.  
```python
t1 = torch.tensor([1,1,1])
t2 = torch.tensor([2,2,2])
t3 = torch.tensor([3,3,3])

torch.cat(
    (t1,t2,t3),
	dim=0    # 由于不存在第二个轴, 为 1 时会报错
)
# tensor([1, 1, 1, 2, 2, 2, 3, 3, 3])

torch.stack(
    (t1,t2,t3),
	dim=0    # 会添加第二个轴, 1 与 0 效果相同, 所以为什么要指定轴?
)
# tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]])
```

在 tensorflow 中 使用 concat 与 stack, dim(维度) 使用 axis(轴) 代替.  
在 numpy 中是 concatenate 与 stack, 使用 axis.  

叠加的操作也可以使用拼接实现:  
```python
torch.cat(
	(
		t1.unsqueeze(0),
		t2.unsqueeze(0),
		t3.unsqueeze(0),
	),
	dim = 0
)
```
stack 的原理也是如此, 先扩展维度, 在调用拼接函数.  


### TensorBoard


其原本为 tensorflow 的可视化工具, pytorch 从1.2.0开始支持 tensorboard.  
tensorboard 是一个前端web界面, 它从一个文件中读取数据, 进行显示.  
可以跟踪和可视化一些指标, 比如 损失和准确率.  

tensorboard可以通过pip安装, 由于其依赖TensorFlow, 所以会自动安装TensorFlow.  
启动命令: 命令行输入, `tensorboard --logdir=<directory_name>`.  

数据的获取(跟踪):  
```python
# ...
form torch.utils.tensorboard import SummaryWriter

tb = SummaryWriter()

images, labels = next(iter(tran_loader))
grid = torchvision.utils.make_grid(images)    # 创造图像网格

tb.add_image('images', grid)    # 图像可视化
tb.add_graph(network, images)   # 神经网络可视化
tb.add_scalar('name', <loss>, epoch)    # 添加标量
tb.add_histogram('name', network.conv1.bias, epoch)   
# 添加直方图, 除了bias, 还可以有weight, weight.grad等等
# ...
tb.close()
```

通过tensorboard可以便捷地对多个不同超参数下的模型进行各项数据的对比.  


### Run Builder/Manager


RunBuilder类可以实现多个不同超参数进行组合(笛卡尔积)训练模型, 能够方便地调试超参数进行测试.  

```python
from collections import OrderedDict, namedtuple
from itertools import product

class RunBuilder():
	@staticmethod
	def get_runs(params):
		Run = namedtuple('Run', params.keys())
		
		runs = []
		# product函数会创建笛卡尔积
		for v in product(*params.values()):
			runs.append(Run(*v))
		
		return runs

params = OrderedDict(
	lr = [.01, .001],    # learn rate
	batch_size = [1000, 10000]
)

runs = RunBuilder.get_runs(params)
# runs = 
# [Run(lr=0.01, batch_size=1000),
# Run(lr=0.01, batch_size=10000),
# Run(lr=0.001, batch_size=1000),
# Run(lr=0.001, batch_size=10000)]
```
> Run 是一个名字为 "Run" 的元组, 其元素可以元素的名字访问, 如:  
> `runs[0].lr`, `runs[0].batch_size`.  


Run Manager类可以用来管理运行(训练)中的的各种参数, 并将其传给TensorBoard.  
便于观察和参数参数.  
```python
class RunManager():
	def __init__(self):
		
		self.epoch_count = 0
		self.epoch_loss = 0
		self.epoch_num_correct = 0
		self.epoch_start_time = None
		
		self.run_params = None    # 网络的参数
		self.run_count = 0        # 训练次数, 即超参数的组合个数
		self.rundata = []         # 储存运行结果
		self.run_start_time = None
		
		self.network = None
		self.loader = None
		self.tb = None
	
	def begin_run(self, run, network, loader):
		self.run_start_time = time.time()
		self.run_params = run
		self.run_count +=1
		
		self.network=network
		self.loader = loader
		self.tb =SummaryWriter(comment=f'-{run}')
		
		images, labels = next(iter(self.loader))
		grid = torchvision.utils.make_grid(images)
		
		self.tb.add_image('images', grid)
		self.tb.add_graph(self.network,images)
	
	def end_run(self):
		self.tb.close()
		self.epoch_count = 0
	
	def begin_epoch(self):
		self.epoch_start_time = time.time()
		
		self.epoch_count += 1
		self.epoch_loss = 0
		self.epoch_num_correct = 0
	
	def end_epoch(self):
		epoch_duration = time.time() - self.epoch_start_time
		run_duration = time.time() - self.run_start_time
		
		loss = self.epoch_loss / len(self.loader.dataset)
		accuracy = self.epoch_num_correct / len(self.loader.dataset)
		
		self.tb.add_scalar('Loss',loss, self.epoch_count)
		self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)
		
		for name, param in self.network.named_parameters():
			self.tb.add_histogram(name, param, self.epoch_count)
			self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)
		
		results = OrderedDict()
		results["run"] = self.run_count
		results["epoch"] = self.epoch_count
		results['loss'] = loss
		results["accuracy"] = accuracy
		results['epoch duration'] = epoch_duration
		results['run duration'] = run_duration
		for k,v in self.run_params._asdict().items(): 
			results[k] = v
		self.run_data.append(results)
		df = pd.DataFrame.from_dict(self.run_data, orient='columns')
		
		clear_output(wait=True)
		display(df)
	
	# 跟踪损失值
	def track_loss(self, loss):
		self.epoch_loss += loss.item() * self.loader.batch_size
	
	# 跟踪准确率
	def tack_num_correct(self, preds, labels):
		self.epoch_num_correct += self._get_num_correct(preds, labels)
	
	@torch.no_grad()
	def _get_num_correct(self, preds, labels):
		return preds.argamx(dim=1).eq(labels).sum().item()
	
	def save(self, fileName):
		pd.DataFrame.from_dict(
			self.run_data,
			orient='columns'
		).to_csv(f'{fileName}.csv')
		
		with open(f'{fileName}.json', 'w', encoding='utf-8') as f:
			json.dump(self.run_data, f, ensure_ascii=False, indent=4)
```

![运行管理](../../image/机器学习/运行管理.png)  

![Run Manager演示](../../image/机器学习/Run%20Manager演示.png)  

- DataLoader的num_workers属性:  
	DataLoader 的参数中有个 num_workers, 表示可工作的核心数量, 默认值为0.  
	当其设置为 1 或者更多时, 可以加快数据的准备速度, 也加快了训练的速度(20%).  
	但其设置过多时(10+), 却产生反作用, 拖累训练的速度.  
	num_workers 的具体影响数值与实际情况相关, 但加上一两个总没错.  


### 使用GPU


英伟达(NVIDIA)的显卡(GPU)拥有一个通用并行计算架构 -- CUDA.  
通过 cuda, 可以利用GPU来进行计算, 极大提高计算速度.  
cuda的安装自行搜索教程.  

`device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")`  

想利用GPU, 需要将 **模型** 和 **数据** 都搬到GPU上:  
`network = network.to(device)`, 数据同理.  
或者 `network = network.cuda()` 和 `network = network.cpu()` 也可以.  










## 训练模型实践


### 手写数字识别模型

堪称AI界的 "hello world".  

```python
import numpy as np  
import torch  
import torch.nn as nn  
import torch.optim as optim  
import torchvision  
import torchvision.transforms as transforms  
import matplotlib.pyplot as plt  
from PIL import Image  


def load():  
    # 数据预处理转换  
    transform = transforms.Compose([  
        transforms.ToTensor(),  # 将图像转换为PyTorch张量  
        transforms.Normalize((0.5,), (0.5,))  # 标准化图像数据，将像素值缩放到[-1, 1]  
    ])  
  
    # 下载MNIST数据集并创建数据加载器：  
    batch_size = 64  
    # 数据集已存在时自动载入  
    root = './data'
    train_dataset = torchvision.datasets.MNIST(root=root, train=True, transform=transform, download=True)  
    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  
  
    test_dataset = torchvision.datasets.MNIST(root=root, train=False, transform=transform, download=True)  
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)  
  
    return train_loader, test_loader  
  
  
# CNN 模型  
class CNN(nn.Module):  
    def __init__(self):  
        super(CNN, self).__init__()  
        # 卷积层  
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)  
        # 池化层  
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  
        # 全连接层  
        self.fc1 = nn.Linear(32 * 12 * 12, 120)  
        self.fc2 = nn.Linear(120, 84)  
        self.fc3 = nn.Linear(84, 10)  
  
    def forward(self, x):  
        x = self.pool(torch.relu(self.conv1(x)))  
        x = x.view(-1, 32 * 12 * 12)  
        x = torch.relu(self.fc1(x))  
        x = torch.relu(self.fc2(x))  
        x = self.fc3(x)  
        return x  


# 训练过程  
def train_model(train_loader, model):  
    # 损失函数和优化器  
    criterion = nn.CrossEntropyLoss()  
    optimizer = optim.Adam(model.parameters(), lr=0.001)  
  
    # 训练模型  
    # 对整个数据集迭代的次数  
    num_epochs = 10  
  
    for epoch in range(num_epochs):  
        running_loss = 0.0  
        for i, data in enumerate(train_loader, 0):  
            # 每次拿到一个 batch 分组
            inputs, labels = data
            # 将输入数据移到GPU上以匹配模型的数据类型  
            inputs, labels = inputs.to(device), labels.to(device)  
            optimizer.zero_grad()   # 清零梯度  
            outputs = model(inputs)  
            loss = criterion(outputs, labels)  
            loss.backward()     # 计算梯度  
            optimizer.step()    # 更新梯度  
            running_loss += loss.item()  
  
        print(f"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}")  
  
    print("Training Finished")  
  
  
def test_model(test_loader, model):  
    # 测试模型  
    correct = 0  
    total = 0  
    
    with torch.no_grad():  
        for data in test_loader:  
            images, labels = data  
            # GPU  
            images, labels = images.to(device), labels.to(device)  
			
            outputs = model(images)  
            _, predicted = torch.max(outputs.data, 1)  
            total += labels.size(0)  
            correct += (predicted == labels).sum().item()  
  
    print(f"Accuracy on test images: {100 * correct / total}%")  
  
  
def print_image(loader):  
    images, labors = next(iter(loader))    # 图像和标签, 为一组数据, 大小等于 batch 的大小  
    # print(images.shape, labors.shape)  
  
    img = torchvision.utils.make_grid(images)   # 将一批图像转换为图像网格  
    img = img / 2 + 0.5  # 反标准化，将张量值从[-1, 1]范围映射到[0, 1]  
    npimg = img.numpy()     # 将PyTorch张量转换为NumPy数组  
  
    # 使用np.transpose将通道维度从(C, H, W)转换为(H, W, C)，以便 Matplotlib 正确显示图像  
    plt.imshow(np.transpose(npimg, (1, 2, 0)))  
    plt.show()  
  
  
def eval_model():  
    model_f = CNN()  
  
    # 加载模型权重  
    model_f.load_state_dict(torch.load('model.pth'))  
    # 设置模型为评估模式（不进行梯度计算）  
    model_f.eval()  
  
    # 加载测试图片并进行相应的预处理（与训练数据相同的预处理）  
    transform = transforms.Compose([  
        transforms.Resize((28, 28)),  
        transforms.Grayscale(num_output_channels=1),  # 将图像转换为单通道灰度图像  
        transforms.ToTensor(),  
        transforms.Normalize((0.5,), (0.5,))  
    ])  
  
    while 1:  
        if input("手写数字识别\n测试: 1, 结束: 0\n") == "1":  
            path = input("输入图片路径:")  
            image = Image.open(path)  # 截图文件路径及其名称  
  
            # 颜色反转  
            inverted_image = Image.new("RGB", image.size)  
  
            for x in range(image.width):  
                for y in range(image.height):  
                    pixel = image.getpixel((x, y))  
                    inverted_pixel = tuple(255 - value for value in pixel)  
                    inverted_image.putpixel((x, y), inverted_pixel)  
  
            # 进行预处理  
            image = transform(inverted_image)  
  
            # 使用模型进行推理  
            with torch.no_grad():  
                output = model_f(image.unsqueeze(0))  # 将图像转换为模型所需的批次维度  
                _, predicted = torch.max(output, 1)  
                print(f"识别结果: {predicted.item()}")  
                print("----------")  
        else:  
            break  
  
  
if __name__ == "__main__":  
      
    if input("1. 训练  2. 测试\n") == "1":  
        print("开始载入数据...")  
        train, test = load()  
        # print_image(train)  
        
	    model = CNN()  
		
        # 检查是否有可用的GPU  
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  
	    
        # 将模型移到GPU上  
        model.to(device)  
          
        print("开始训练...")  
        train_model(train, model)  
          
        test_model(test, model)  
	    
        # 保存模型参数, 将保存模型的权重到名为 mnist_cnn_model.pth 的文件中  
        print("保存模型中...")  
        torch.save(model.state_dict(), 'model.pth')
        print("保存成功.")
	  
    else:  
        eval_model()
```

![训练输出](D:\word文档\MarkDown文档\image\机器学习\手写数字识别训练结果.png)  

- 对于 FashionMNIST 训练集, 准确率只能达到 90%+  