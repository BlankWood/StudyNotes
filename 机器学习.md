**机器学习(Machine Learning)**

机器学习是从数据中自动分析获得模型, 并利用模型对未知数据进行预测.  

- 机器学习是人工智能的一个实现途径.  
- 深度学习是机器学习的一个方法发展而来.  

# 介绍

## 机器学习工作流程

1. 获得数据  
一行数据称为一个样本, 一列称为一个特征, 有些数据有目标值(标签值), 有些没有.数据一般分出20%~30%用于测试.  

2. 数据基本处理  
对数据进行缺失值,去除异常值等处理.  

3. 特征工程  
(专业的数据处理, 机器对特征的识别直接影响机器学习的效果以及上限), 包括:  
    - 特征提取
    - 特征预处理
    - 特征降维

4. 机器学习(模型训练)  
5. 模型评估  

## 人工智能主要分支

- 计算机视觉
- 语音识别
- 文本挖掘/分类
- 机器翻译
- 机器人

## 机器学习算法

- 监督学习

输入数据由输入特征值和目标值组成, 输出可以是一个连续的值(回归), 或是有限个离散的值(分类).  

    - 回归问题: 数据可由函数表示.
    - 分类问题: 数据可分类.

- 无监督学习

输入数据由特征值组成, 没有目标值.

- 半监督学习
- 强化学习 

## 模型评估

### 分类模型评估
准确率, 精确率, 召回率, F1-score, AUC指标等.  
主要学习准确率.  

### 回归模型评估
均方根误差(RMSE)是一个衡量回归模型误差率的常用格式.

### 拟合

- 欠拟合: 模型学习过于粗糙, 对数据特征关系要求过低.
- 过拟合: 对数据特征要求过高

## 深度学习

深度学习也称为深度结构学习, 层次学习, 深度机器学习. 基于神经网络发展而来...  

# 常用科学计算库

## matplotlib模块

| 方法 | 说明 |
| --- | --- |
| figure(figsize=(), dpi=) | 创建画布, figsize为图的长宽, fig为清晰度 |
| plot(x:list, y:list) | 绘制折线 |
| scatter() | 绘制散点图 |
| bar() | 绘制柱状图 |
| hist(x, bins) | 绘制直方图, bins为组距 |
| pie() | 绘制饼图 |
| show() | 显示图像 |
| xticks(list) | 修改x轴刻度 |
| grid(True, linestyle='--', alpha=0.5) | 添加网格线, '--'表示虚线, alpha为透明度(0-1) |
| xlabel(str) | 添加x轴描述信息 |
| title(str) | 添加标题 |
| savefig(str) | 保存图像, 参数为保存路径, 需要在show()之前 |
| legend(loc="best") | 显示图例, 参数为位置 |


```
# 图像中中文字体无法显示, 可修改配置文件或暂时修改配置:
from pylab import mpl
# 设置显示中文字体, 字体需要自行下载并安装
mpl.rcParams["font.sans-serif"] = ["SimHei(字体名)"]
# 防止部分字符无法正常显示
mpl.rcParams["axes.unicode_minus"] = False

import matplotlib.pyplot as plt
# 创建画布
plt.figure(figsize=(20, 8), dpi=100)
# 绘制图像
# 获取x,y轴数据
x = range(60)
y_temper = [random.uniform(15, 18) for i in x]
# 添加x,y轴
# 多次plot可获得多条折线
plt.plot(x, y_temper)
# 获取x, y轴刻度
x_ticks_label = ["11点{}分".format(i) for i in x]
y_ticks = range(40)
# 修改x, y轴刻度
# 坐标刻度不可以直接通过字符串修改
# plt.xticks(x_ticks_label[::5])
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])

plt.xlabel("时间")
plt.ylabel("温度")
# 图像显示
plt.show()
```

## Numpy

Numpy是一个开源的Python科学计算库, 用于快速处理任意维度的数组.  
Numpy支持常见的数组和矩阵操作.  
Numpy使用ndarray对象来处理多维数组,该对象是一个快速而灵活的大数据容器.  

| 方法 | 说明 |
| --- | --- |
| numpy.array(list) | 返回n维数组, 参数为n维的数组 |
| ones/zeros([n, m]) | 生成n行m列的1/0数组 |
| ones/zeros_like(array) | 生成大小与array相同的n维1/0数组 |
| linspace(start, stop, num, endpoint) | 生成等差数列, num为元素个数(默认50), endpoint表示是否包含stop值(默认ture) |
| arange(start, stop, step, dtype) | 创建等差数组, step为步长(默认1) |
| logspace(start, stop, num) | 创建等比数列, num为元素个数(默认50) |
| random.normal(loc, scale, size) | 生成size个正态分布的随机数, 均值为loc, 标准差为scale |
| random.uniform(low, high, size) | 生成size个均匀分布的随机数, 范围: low-high |
| reshape(shape, order) | 返回一个具有相同数据域, 但shape不同 |
| resize(new_shape) | 修改数组本身的形状 |
| T | 转置符, 调用后将矩阵转置 |
| astype(type) | 返回修改元素数据类型之后的数组, type为某数据类型 |
| tostring() | 转为sting |
| numpy.unique(array) | 将传入的数组去重 |


- reshape(shape):  
shape, 应为一个数组[x, y, z, ...], 表示每行每列等的原素个数, 如: [3, 4, 2], -1 表示不确定的个数, [-1, 5]表示行数不确定, 但只有2列.  有-1时, 如果形状不能完全填充就会报错. 

- 切片:  
多维数组也可以进行切片, narray[n:m, x:y], 按维度一个一个切, 中间用 "," 隔开.  

### ndarray运算

1. 逻辑运算:  
    ```
    import numpy as np

    # 生成10行5列, 40-100之间的随机整数
    score = np.random.randint(40, 100, (10, 5))

    # 切出后四行数据用于测试
    test_score = score[6: , 0:5]

    test_score[test_score > 60] = 1
    ```

2. 通用判断函数:  
    - all(): 判断元素是否全部符合条件。
    - any(): 判断是否存在符合条件的元素。

    ```
    # 数据接第一部分
    # 切取前两名学生的成绩
    np.all(score[0:2, :] > 60)

    np.any(score[0:2, :] > 90)
    ```

3. np.where(三元运算符):  
    ```
    temp = score[:4, :4]

    np.where(temp > 60, 1, 0)

    np.where(np.logical_and(temp > 60, temp < 90), 1, 0)

    np.where(np.logical_or(temp > 90, temp < 60), 1, 0)
    ```

4. 统计运算

    | 运算 | 说明 |
    | --- | --- |
    | min(a, axis) | 返回最小值 |
    | max(a, axis) | 返回最大值 |
    | median(a, axis) | 计算中位数 |
    | mean(a, axis, dtype) | 计算平均值 |
    | std(a, axis, dtype) | 计算标准差 |
    | var(a, axis, dtype) | 计算方差 |
    | argmin/argmax(a, axis) | 返回最小/大值对应的下标 |


    - a为数组
    - axis为行或列, 会计算每行(列)的最大值等. 可以为空, 此时统计范围为全部数据.  

### 数组间的运算

1. 数组与数的运算
    ```
    a = np.array([[1,2,3], [3,4,5]])

    a + 3   # 全部元素都会 +3
    a / 2   # 全部元素都会 /2

    a = [1, 2, 3]   # 列表

    a * 3   # 列表会复制成3份, [1,2,3,1,2,3,1,2,3]
    ```

2. 数组与数组的运算

    不同形状数组之间的相加会通过**广播机制**进行扩展, 使两数组形状相同, 只要满足下面其中一个条件:  
    - 维度相同, 对应维度长度相同, 或其一为1.
    - 维度不同, 低维数组前扩展维度, 长度为1, 然后看其他维度长度.  

### 矩阵与向量

矩阵可以看作二维数组, 向量为 n x 1 的数组.  

知识详情见线性代数.  

矩阵乘法: np.matmul(a, b), np.dot()  
- matmul中不支持矩阵与标量相乘.  

## Pandas

### 简介

- 专门用于数据挖掘的开源python库
- 以Numpy为基础
- 基于matplotlib, 能够简便画图
- 独特的数据结构

### pandas的数据结构

#### series(一维数组)

- 创建: pandas.Series(data, index= , dtype= )
    - data也可以为字典, 此时索引即为对应的key.  
    - index: 索引, 必须唯一, 且与数据长度等长. 如果没有传入则自动创建0-N的整数索引.  
    - dtype: 数据的类型, 可省略.  
- 属性(可直接访问):  
    - index: 索引
    - values: 值
    还可以通过 <series数组名>[下标] 的方式访问对应的值.  

#### DataFrame(二维数组)

- 创建: pd.DataFrame(data, index= , columns= )
    - index: 行标签, 可以为string列表, 默认0-N.  
    - columns: 列标签, 可以为string列表, 默认0-N.  
- 属性: shape, index, columns, value...    
    - T: 转置
    - head(n): 获取前n行数据, n默认为5.  
    - tail(n): 获取后n行数据, n默认为5.  
- 设置索引: <DataFrame对象名>.index/columns = list.  
    - 重置索引方法: reset_index(drop=True)  drop默认为false.
    - 以某列为索引: set_index(key, drop=True)  drop默认为True.

#### MultiIndex与Panel

MultiIndex: 多级索引(层次化索引), 是pandas的重要功能. Series, Data Frame对象内也有MultiIndex对象.  

- 创建: pd.MultiIndex.from_arrays(arrays, name= )
    - arrays: 索引列表, 二维string数组.
    - name: string数组, 代表每个索引的名字.
- 属性:  
    - names: 索引的名字
    - levels: 索引(有序列表)
    - labels: 索引对应的顺序

拥有三个索引的数组就是三维数组, panel为储存三维数组的容器.  

- 创建: pandas.Panel(data, items, major_axis, minor_axis)
    - 参数为数据与三个索引

无法直接查看, 只能先切成二维数组再查看.  

### 基本数据操作

#### 索引操作

1. <容器名>[列下标][行下标] 或 <容器>.下标 获取对应元素.  
2. <容器>.loc["索引1" : "索引2", ...] : 获取从索引1到索引2的数据, 索引值.  
3. <容器>.iloc[x1 : x2, ...] : 获取第x1到第x2的数据, 索引下标.  

#### 排序

- sort_values(by= , ascending= ) : 根据值排序
    - by: 排序依据的索引(依据哪个索引排序), 可以为多个.  
    - ascending: 默认为True(升序), False为降序.  

- sort_index() : 按索引值排序.  

### DataFrame运算

- 算术运算  
    <容器>[索引值].add(...) 或 <容器>[索引值] + ...(不推荐)  

- 逻辑运算  
    <容器>[索引值] > ...  
    <容器>.query(expr:string) : expr为查询字符串, 形式为: "索引值 > 60 & 索引值 < 80 ", 此时此索引下的值大于60且小于80的会返回true.  
    <容器>[索引值].isin(values) : 判断此索引下的数据是否再某个范围之间, values为有两个元素的list.

- 统计运算
    - describe(): 综合分析, 能够直接得出count, mean, std, min, max等
    - 个单独的统计函数, sum, mean等, 具体可参考Numpy.  

- 自定义运算: apply(fun, axis=0)
    - fun: 自定义函数
    - axis: 默认(0)为列, 1为行

### Pandas画图

Series/DataFrame.plot(kind), Series或DataFrame对象可直接调用plot进行绘制图像, 参数为图像的种类, 默认为"line(折线图)".  

### 文件读取与存储

pandas支持多种文件格式的读取, 包括 CSV, Json, HTML, Lacol, HDF等.  

#### CSV(.csv)

- pandas.read_csv(filepath_or_buffer, sep=',')
    - filepath_or_buffer: 文件路径.  
    - usecols: 指定读取的列名, 列表形式.
- DataFrame.to_csv(path_or_buf, sep=',', columns=None, header=True, index=True, mode='w')  
    - sep: 分隔符,默认为','.
    - columns: 需要写入的列索引.
    - header: 是否写入列索引值, 默认True.
    - index: 是否写入行索引值.
    - mode: 'w'为写入, 'a'为追加.

#### HDF5(.h5)

- pandas.read_hdf(path_or_buf, key=None) 
- DataFrame.to_hdf(path_or_buf, key)

HDF5文件的读取和存储需要指定一个键, 值为要存储的DataFrame.  
优先选择使用HDF5文件存储.  
1. HDF5在存储时支持压缩, 使用的方式为blosc, 这个是速度最快的也是pandas默>支持的.  
2. HDF5支持跨平台, 可以轻松迁移到Hadoop上面.  

#### Json(.json)

- read_json(path_or_buf, orient, typ='frame', lines=False)
    - 将JSON格式转化成默认的Pandas DataFrame格式.  
    - orient: 数据的显示形式  
        - split: 行索引, 列索引, 数据分开.
        - records: 以 columns : values 的形式输出.  
        - index: 以 index : {columns : values} 的形式输出.  
        - columns: 以 columns : {index : values} 的形式输出.  
        - values: 直接输出值
    - typ: 转换成的数据为dataframe或series.  
    - lines: 按照行读取.  

- to_json(path, orient, lines)

### 高级处理

#### 缺失值处理

1. 缺失值标记为NaN

    - 判断  
        - pd.isnull(df)  
        - pd.notnull(df)
        - 一般配合np.all()与np.any()使用.  
    - 处理  
        - 删除: dropna(axis='rows')  
            - 不会修改原数据, 需要接收返回值  
        - 替换: fillna(value, inplace=True)  
            - values: 替换值  
            - inplace: 是否修改原数据, false则返回新数据  

2. 不是NaN, 例如"?"  
    
    - 先替换为np.nan, 然后继续处理.  
    - df.replace(to_replace='?', value=np.nan)

#### 数据离散化

- 目的：  
连续属性离散化的目的是为了简化数据结构, 数据离散化技术可以用来减少给定连续属性值的个数。离散化方法经常作为数据挖掘的工具。  

- 具体内容：  
连续属性的离散化就是在连续属性的值域上，将值域划分为若干个离散的区间，最后用不同的符号或整数值代表落在每个子区间中的属性值。  
例如：有一组身高数据(连续属性)，将身高划分为几个区间：150~165、165~180，180~195，并标记为矮、中、高三个类别，最终要处理成一个"哑变量"矩阵。  
也就是用矮、中、高代替身高数据。  

- 方法:  
    - pd.qcut(data, q)  # 将数据自动分成数量差不多的q组  
    - series.value_counts()    # 统计分组数据数量  
    - pd.cut(data, bins)    # bins为自己指定的分组区间, 例:[0,5,10]  

将分组可以转化为表格: 横轴为各区间, 纵轴为数据下标, 值为1表示在此区间.  
- pd.get_dummies(p_count, prefix:string)   # p_count为分好的组, prefix为区间的前缀取名.  

#### 合并

- pd.concat([data1, data2], axis=1)  
    将两表按照行或列进行合并, axis=0(默认)为列索引, 1为行索引.  

- pd.merge(left, right, how="inner", on=None)  
    - 可以指定按照两组数据的共同键值对合并或者左右各自  
    - left: DataFrame  
    - right: 另一个DataFrame  
    - on: 指定的共同键
    - how: 按照什么方式连接, 默认内连接  

| Merge method | SQL Join Name |
| --- | --- |
| left | 左连接 |
| right | 右连接 |
| outer | 外连接 |
| inner | 内连接 |

#### 交叉表与透视表

交叉表：用于计算一列数据对于另一列数据的分组个数(用于统计分组频率的特殊透视表)  
- pd.crosstab(value1, value2)

透视表: 将原有的DataFrame的列分别作为行索引和列索引, 然后对指定的列应用聚集函数.  
- data.pivot_table()  
- DataFrame.pivot_table([], index)

